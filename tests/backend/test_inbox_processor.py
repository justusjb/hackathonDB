# /Users/justus/PycharmProjects/hackathonDB/tests/backend/test_inbox_processor.py
import pytest
from pymongo.database import Database

# Assuming your project structure allows these imports from the 'tests' dir
# If not, you might need to adjust PYTHONPATH or project configuration
from backend.inbox_processor import process_scraped_items, is_duplicate
from backend.scrapers.mock_scraper import MockScraper
from backend.database import get_db # To get the DB connection
from shared_models.models import InboxItem, Hackathon, DateRange, HackathonStatus, InboxStatus # Import necessary models
from datetime import datetime, timedelta, timezone

# --- Pytest Fixtures ---

@pytest.fixture(scope="function") # Run for each test function
def db() -> Database:
    """Provides a connection to the test database and cleans up relevant collections afterwards."""
    database = get_db()
    print(f"\n--- Using database: {database.name} ---") # For visibility during test runs
    assert "pytest" in database.name # Safety check: Ensure we're not using prod/staging DB

    # Clean relevant collections before the test runs
    print("--- Cleaning inbox_items and hackathons collections ---")
    database['inbox_items'].delete_many({})
    database['hackathons'].delete_many({})

    yield database # Provide the database object to the test

    # Teardown (optional): Clean up again after the test if desired
    # print("--- Cleaning up collections post-test ---")
    # database['inbox_items'].delete_many({})
    # database['hackathons'].delete_many({})


@pytest.fixture(scope="session") # Run once per test session
def mock_items() -> list[InboxItem]:
    """Provides the list of items generated by the MockScraper."""
    scraper = MockScraper()
    return scraper.scrape()


# --- Test Functions ---

def test_process_new_items(db: Database, mock_items: list[InboxItem]):
    """
    Test inserting genuinely new items.
    Uses a subset of mock_items guaranteed to be unique for this test.
    """
    # Select specific items known to be unique from the mock data for this test
    # Example: items 1 and 2 from MockScraper are likely unique initially
    new_items_to_process = [item for item in mock_items if "Alpha" in item.name or "Beta" in item.name]
    assert len(new_items_to_process) >= 2, "Test setup error: Need at least 2 unique mock items"

    # Sanity check: Ensure DB is empty before processing
    inbox_collection = db['inbox_items']
    assert inbox_collection.count_documents({}) == 0

    # --- Act ---
    process_scraped_items(new_items_to_process)

    # --- Assert ---
    # Check that the correct number of items were inserted
    assert inbox_collection.count_documents({}) == len(new_items_to_process)

    # Check details of one inserted item (optional but good)
    inserted_item_doc = inbox_collection.find_one({"name": "MockHacks Alpha"})
    assert inserted_item_doc is not None
    assert inserted_item_doc['review_status'] == InboxStatus.PENDING.value # Check status
    assert inserted_item_doc['url'] == "https://example.com/mockhacks-alpha"

    # Validate the inserted document using the Pydantic model (optional but robust)
    try:
        InboxItem.model_validate(inserted_item_doc)
    except Exception as e:
        pytest.fail(f"Inserted document for 'MockHacks Alpha' failed Pydantic validation: {e}")


def test_skip_duplicate_in_inbox(db: Database, mock_items: list[InboxItem]):
    """Test that an item already present in inbox_items (by URL) is skipped."""
    inbox_collection = db['inbox_items']
    hackathons_collection = db['hackathons']

    # --- Arrange ---
    # Find the item we want to pre-insert (e.g., the one with the duplicate URL)
    item_to_duplicate = next((item for item in mock_items if item.url == "https://example.com/duplicate-hackathon"), None)
    assert item_to_duplicate is not None, "Test setup error: Cannot find duplicate item in mock data"

    # Manually insert this item into the inbox collection *before* processing
    # Use the same serialization logic as process_scraped_items
    item_dict = item_to_duplicate.model_dump(mode='python', by_alias=True)
    if '_id' in item_dict and item_dict['_id'] is None: del item_dict['_id']
    item_dict['review_status'] = InboxStatus.PENDING.value # Set status explicitly
    insert_result = inbox_collection.insert_one(item_dict)
    print(f"Pre-inserted item ID into inbox: {insert_result.inserted_id}")
    assert inbox_collection.count_documents({}) == 1
    assert hackathons_collection.count_documents({}) == 0

    # --- Act ---
    # Process ALL mock items (including the one we just inserted)
    process_scraped_items(mock_items)

    # --- Assert ---
    # The total count should be the number of unique URLs MINUS the one already present PLUS the one we added initially.
    # Mock items have 5 unique URLs. One was pre-inserted. So 4 new ones should be added. Total = 1 (pre-inserted) + 4 (new) = 5
    expected_final_count = len({item.url for item in mock_items if item.url}) # Count unique URLs
    assert inbox_collection.count_documents({}) == expected_final_count

    # Verify the specific pre-inserted item wasn't modified significantly (e.g., status)
    # Note: Finding by URL here
    final_item_doc = inbox_collection.find_one({"url": str(item_to_duplicate.url)})
    assert final_item_doc is not None
    assert final_item_doc['_id'] == insert_result.inserted_id # Should be the same document
    assert final_item_doc['review_status'] == InboxStatus.PENDING.value # Status should remain PENDING

    # Ensure nothing was added to the main hackathons collection
    assert hackathons_collection.count_documents({}) == 0


def test_skip_duplicate_in_main_collection(db: Database, mock_items: list[InboxItem]):
    """Test that an item already present in the main hackathons collection (by URL) is skipped."""
    inbox_collection = db['inbox_items']
    hackathons_collection = db['hackathons']

    # --- Arrange ---
    # Find an item to pre-insert into the main collection
    item_to_duplicate = next((item for item in mock_items if "FakeConf Beta" in item.name), None)
    assert item_to_duplicate is not None

    # Manually insert into the *hackathons* collection
    # We need a valid Hackathon object - create one based on the InboxItem
    hackathon_data = item_to_duplicate.model_dump(mode='python', exclude={'review_status', 'scraped_at', 'source_url', 'scraper_name'}) # Exclude inbox-specific fields
    hackathon_data['status'] = HackathonStatus.UPCOMING # Give it a valid status
    hackathon = Hackathon.model_validate(hackathon_data)
    hackathon_dict = hackathon.model_dump(mode='python', by_alias=True)
    if '_id' in hackathon_dict and hackathon_dict['_id'] is None: del hackathon_dict['_id']

    insert_result = hackathons_collection.insert_one(hackathon_dict)
    print(f"Pre-inserted item ID into hackathons: {insert_result.inserted_id}")
    assert hackathons_collection.count_documents({}) == 1
    assert inbox_collection.count_documents({}) == 0

    # --- Act ---
    process_scraped_items(mock_items)

    # --- Assert ---
    # All items from mock_items EXCEPT the one matching the URL in hackathons should be in the inbox
    expected_inbox_count = len({item.url for item in mock_items if item.url}) - 1
    assert inbox_collection.count_documents({}) == expected_inbox_count

    # Check that the specific duplicated item is NOT in the inbox
    assert inbox_collection.find_one({"url": str(item_to_duplicate.url)}) is None

    # Ensure the main collection wasn't touched
    assert hackathons_collection.count_documents({}) == 1


# TODO: Add more tests?
# - Test for item without URL (ensure it's handled - currently assumed not duplicate)
# - Test edge cases in is_duplicate if logic becomes more complex (e.g., name/date checks)
